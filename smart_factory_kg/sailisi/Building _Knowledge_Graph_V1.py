# -*- coding: utf-8 -*-
import os
import json
import pandas as pd
from neo4j import GraphDatabase
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
import re

def read_table_headers(file_path):
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
    ext = os.path.splitext(file_path)[-1].lower()
    if ext in ['.xlsx', '.xls']:
        df = pd.read_excel(file_path)
    elif ext == '.csv':
        df = pd.read_csv(file_path)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {ext}")
    return df.columns.tolist()

def clean_json_string(text):
    if text.strip().startswith("```"):
        return re.sub(r"```[a-zA-Z]*\n?", "", text).strip()
    return text.strip()

def extract_kg_from_headers(headers, llm, manual_labels=None):
    if manual_labels:
        labels_text = "ã€".join(manual_labels)
        system_prompt = (
            "ä½ æ˜¯ä¸€ä¸ªä¿¡æ¯æŠ½å–ä¸“å®¶ã€‚æˆ‘ä»¬éœ€è¦ä»è¡¨å¤´ä¸­æå–ä¾›åº”é“¾è´¨é‡ç®¡ç†ç›¸å…³çš„ç»“æ„ä¿¡æ¯ã€‚\n"
            f"ä»¥ä¸‹æ˜¯ç”¨æˆ·æŒ‡å®šçš„å®ä½“æ ‡ç­¾ï¼š{labels_text}ã€‚\n"
            "è¯·ä»è¡¨å¤´ä¸­æå–æ‰€æœ‰æ»¡è¶³ä»¥ä¸‹æ¡ä»¶çš„ä¸‰å…ƒç»„ï¼ˆhead, head_type, relation, tail, tail_typeï¼‰ï¼š\n"
            "ä»…ä¿ç•™ head_type å’Œ tail_type å±äºä¸Šè¿°æ ‡ç­¾çš„ä¸‰å…ƒç»„ã€‚\n"
            "ä»¥å¦‚ä¸‹JSONæ ¼å¼è¿”å›ï¼ˆä¸è¦åŠ markdownç¬¦å·ï¼‰ï¼š\n"
            "{\n"
            "  \"triples\": [\n"
            "    {\"head\": \"å­—æ®µA\", \"head_type\": \"æ ‡ç­¾X\", \"relation\": \"å…³ç³»\", \"tail\": \"å­—æ®µB\", \"tail_type\": \"æ ‡ç­¾Y\"}\n"
            "  ]\n"
            "}"
        )
    else:
        system_prompt = (
            "ä½ æ˜¯ä¸€ä¸ªä¿¡æ¯æŠ½å–ä¸“å®¶ã€‚æˆ‘ä»¬éœ€è¦å¯¹æ¶‰åŠä¾›åº”é“¾è´¨é‡ç®¡ç†çš„çŸ¥è¯†è¿›è¡Œæå–ï¼Œ"
            "å¦‚æœå†…å®¹ä¸æ¶‰åŠä¾›åº”é“¾è´¨é‡ç®¡ç†ï¼Œå°±ä¸è¿›è¡Œæå–ã€‚è¯·ä»ç”¨æˆ·è¾“å…¥çš„è¡¨å¤´ä¸­æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š\n"
            "1. è¯†åˆ«å¹¶è¾“å‡ºä¸è¶…è¿‡3ç§å®ä½“æ ‡ç­¾ï¼ˆå¦‚ï¼šå…¬å¸ã€äº§å“ã€äººå‘˜ç­‰ï¼‰ï¼Œè®°ä¸ºNode labelsï¼›\n"
            "2. æå–æ‰€æœ‰çŸ¥è¯†ä¸‰å…ƒç»„ï¼ˆhead, head_type, relation, tail, tail_typeï¼‰ï¼›\n"
            "3. ä»…ä¿ç•™head_typeå’Œtail_typeå±äºä¸Šè¿°3ç±»Node labelsçš„ä¸‰å…ƒç»„ã€‚\n"
            "ä»¥å¦‚ä¸‹JSONæ ¼å¼è¿”å›ï¼ˆä¸è¦æ·»åŠ markdownæ ‡è®°ï¼‰ï¼š\n"
            "{\n"
            "  \"labels\": [\"æ ‡ç­¾1\", \"æ ‡ç­¾2\", \"æ ‡ç­¾3\"],\n"
            "  \"triples\": [\n"
            "    {\"head\": \"å­—æ®µA\", \"head_type\": \"æ ‡ç­¾X\", \"relation\": \"å…³ç³»\", \"tail\": \"å­—æ®µB\", \"tail_type\": \"æ ‡ç­¾Y\"}\n"
            "  ]\n"
            "}"
        )

    headers_text = "ã€".join(headers)
    human_input = f"ä»¥ä¸‹æ˜¯è¡¨æ ¼çš„è¡¨å¤´å­—æ®µï¼š{headers_text}"

    response = llm.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content=human_input)
    ])

    raw_text = clean_json_string(response.content.strip())
    print("ğŸ§¾ æ¨¡å‹åŸå§‹å“åº”ï¼š", raw_text)

    try:
        kg_info = json.loads(raw_text)
        if manual_labels:
            triples = [
                t for t in kg_info.get("triples", [])
                if t["head_type"] in manual_labels and t["tail_type"] in manual_labels
            ]
            return {"labels": manual_labels, "triples": triples}
        return kg_info
    except json.JSONDecodeError as e:
        raise ValueError(f"æ¨¡å‹è¿”å›ä¸æ˜¯åˆæ³•JSONæ ¼å¼ï¼š\n{raw_text}") from e

def build_graph_with_alignment(path, kg_info, graph, source_tag):
    df = pd.read_excel(path)
    triples = kg_info.get("triples", [])
    if not triples:
        print("âš ï¸ æ²¡æœ‰å¯å†™å…¥çš„ä¸‰å…ƒç»„ï¼Œå·²è·³è¿‡æ•°æ®åº“å†™å…¥ã€‚")
        return

    with graph.session() as session:
        for _, row in df.iterrows():
            for triple in triples:
                head_col = triple["head"]
                tail_col = triple["tail"]
                relation = triple["relation"]
                head_type = triple["head_type"]
                tail_type = triple["tail_type"]

                head_value = str(row.get(head_col, "")).strip()
                tail_value = str(row.get(tail_col, "")).strip()
                head_code = str(row.get("å®ä½“ä»£ç ", "")).strip()
                tail_code = str(row.get("å…³è”ä»£ç ", "")).strip()

                if not head_value or not tail_value:
                    continue

                cypher = f"""
                MERGE (h:{head_type} {{name: $head, æ¥æº: $source}})
                ON CREATE SET h.ä»£ç  = $head_code

                MERGE (t:{tail_type} {{name: $tail, æ¥æº: $source}})
                ON CREATE SET t.ä»£ç  = $tail_code

                MERGE (h)-[:`{relation}`]->(t)
                """
                session.run(cypher, head=head_value, tail=tail_value,
                            source=source_tag, head_code=head_code, tail_code=tail_code)

    print(f"âœ… [{source_tag}] æ•°æ®å·²å†™å…¥å¹¶å°è¯•æ¶ˆæ­§ã€‚")

def check_entity_alignment(graph, label, name):
    with graph.session() as session:
        query = f"MATCH (n:{label}) WHERE n.name = $name RETURN n"
        result = session.run(query, name=name)
        nodes = list(result)
        print(f"ğŸ” å®ä½“â€œ{name}â€åœ¨æ ‡ç­¾ {label} ä¸‹å…±æ‰¾åˆ° {len(nodes)} ä¸ªèŠ‚ç‚¹ï¼š")
        for record in nodes:
            props = dict(record["n"])
            print(f"- æ¥æº: {props.get('æ¥æº', 'æ— ')}, ä»£ç : {props.get('ä»£ç ', 'æ— ')}")

if __name__ == "__main__":
    file_path = "../data/å°è´¦.xlsx"
    headers = read_table_headers(file_path)
    print("ğŸ“‘ è¡¨å¤´ä¸ºï¼š", headers)

    llm = ChatOpenAI(
        model_name="deepseek-ai/DeepSeek-V3",
        openai_api_key="sk-joyiukvlkwsxvbxliqzepnxawudighulwwuddeahlypadkvq",
        base_url="https://api.siliconflow.cn/v1",
        streaming=False,
        top_p=0.7
    )

    label_input = input("æ˜¯å¦æ‰‹åŠ¨æŒ‡å®šå®ä½“æ ‡ç­¾ï¼Ÿå¦‚éœ€æŒ‡å®šï¼Œè¯·ç”¨é€—å·åˆ†éš”è¾“å…¥ï¼ˆå¦‚ï¼šå…¬å¸,äº§å“,äººå‘˜ï¼‰ï¼Œå¦åˆ™ç›´æ¥å›è½¦ï¼š\n> ").strip()
    manual_labels = [l.strip() for l in re.split(r"[ï¼Œ,]", label_input) if l.strip()] if label_input else None

    kg_info = extract_kg_from_headers(headers, llm, manual_labels=manual_labels)
    print("âœ… æŠ½å–ç»“æ„ï¼š", json.dumps(kg_info, indent=2, ensure_ascii=False))

    graph = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", "idt123456"))

    print("ğŸ“¡ æ­£åœ¨å†™å…¥æ¥æºA...")
    build_graph_with_alignment(file_path, kg_info, graph, source_tag="A")

    # è‹¥æœ‰ç¬¬äºŒä»½æ–‡ä»¶ä¹Ÿå†™å…¥æµ‹è¯•
    file_path_B = "../data/ä¾›åº”å•†è´¨é‡é—®é¢˜å°è´¦.xlsx"
    if os.path.exists(file_path_B):
        print("ğŸ“¡ æ­£åœ¨å†™å…¥æ¥æºB...")
        build_graph_with_alignment(file_path_B, kg_info, graph, source_tag="B")

    # æµ‹è¯•å®ä½“å¯¹é½ç»“æœ
    test_label = manual_labels[0] if manual_labels else "ä¾›åº”å•†"
    test_name = input(f"è¯·è¾“å…¥è¦æ£€æŸ¥å¯¹é½çš„å®ä½“åç§°ï¼ˆé»˜è®¤ä½¿ç”¨â€œé£æµ·ç§‘æŠ€ä¼ åª’æœ‰é™å…¬å¸â€ï¼‰:\n> ").strip() or "é£æµ·ç§‘æŠ€ä¼ åª’æœ‰é™å…¬å¸"
    check_entity_alignment(graph, test_label, test_name)

    print("ğŸ¯ å…¨éƒ¨æµç¨‹ç»“æŸã€‚")
